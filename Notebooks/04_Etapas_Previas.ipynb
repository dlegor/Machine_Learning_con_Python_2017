{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapas Previas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las sección se revisarán aspectos sobre la división entre datos para estimar el modelo y valorar su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etapas antes de estimar modelos\n",
    "\n",
    "En la mayorías de los casos antes de pasar a implementar algún algoritmos de Aprendizaje Automático se realizarán ciertas etapas que pueden ser igual de importantes. No hay una lista precisa ya que siempre depende del proyecto, pero a grandes rasgos pueden considerarse las siguentes:\n",
    "\n",
    "* Integración y limpieza de los datos.\n",
    "* Exploración y visualización de los Datos.\n",
    "* Tranformación, creación y selección de variables.\n",
    "* Elección de algoritmos y medida de sus calidad para el problema.\n",
    "* Presentación de resultados o integración a un sistema.\n",
    "\n",
    "Puede haber más etapas  y pueden alternarse varias de ellas, como quizás al momento de elegir los algoritmos, decidir hacer ciertas transformaciones o crear nuevas variables, o eliminar algunas variables que aportan poco al modelo elegido, etc. Las primeras dos etapas son básicas y pueden consumir mucho tiempo. \n",
    "\n",
    "Focalizando la atención en la \"elección de algoritmos y medida de calidad para el poblema\", que es la etapa que principalmente hace uso de Aprendizaje Automático se busca satisfacer lo siguiete:\n",
    "\n",
    "* Definir las muestras de entrenamiento y prueba.\n",
    "* Entrenar varios modelos sobre una submuestra entrenamiento (train set).\n",
    "* Hacer predicciones sobre otra submuestra de prueba (test set).\n",
    "* Medir la calidad de los modelos y elegir modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train - Test \n",
    "\n",
    "El tema de esta sección es sobre la definición o división de los datos en: entrenamiento y prueba. En la sección previa se hicieron algunos ejemplos con la regresión logística, árboles de decisión y regresión lineal. Se midió su precisión, pero en ningún momento se dividieron los datos entre muestras de entrenamiento y prueba.  \n",
    "\n",
    "<img src=\"./Imagenes/train_test_split_matrix.svg\" height=\"700\" width=\"700\">\n",
    "\n",
    "\n",
    "La finalidad de hacer esta división en los datos tiene un doble sentido, el primero es evitar el [sobreajuste del modelo](https://en.wikipedia.org/wiki/Overfitting). En palabras llanas, se trata de evitar que el modelo sea bueno para estimarse para una muestra de datos, pero cuando le damos datos nuevos (Generalización del Modelo) sobre los cuales no se estimaron los parámetros tenga una pésima calidad de predicción.\n",
    "\n",
    "&nbsp;\n",
    "<img src=\"./Imagenes/Esquema_train_test.png\" height=\"600\" width=\"600\">\n",
    "&nbsp;\n",
    "\n",
    "### No hay receta para dividir los datos\n",
    "\n",
    "No hay una regla precisa, se puede tener en los datos dependencia del tiempo, se puede buscar cuidar que el comportamiento estadístico (la media, la varianza, el balance entre categorías) de las variables sea \"bueno\". También puede no importar mucho la división y basta elegir aleatoriamente datos, o se pueden tener muy pocos datos como para dividir la muestra.\n",
    "\n",
    "En general [recomiendan](https://www.autonlab.org/_media/tutorials/overfit10.pdf tittle=\"Fig.1 Represetanción de la División de Datos\") dividir entre un 70-80% para datos de entrenamiento y un 30-20% para datos de prueba o validación.\n",
    "\n",
    "### Conjunto de Validación\n",
    "\n",
    "Se planea la siguiente pregunta,*¿Qué hacer para saber si la elección de los parámetros de alguno de los algoritmos es \"bueno\" ante datos nuevos?*\n",
    "\n",
    "Si bien se dividió entre los conjuntos de Entrenamiento/Prueba; quizás si la muestra de datos es muy pequeña o el modelo tienen muchos parámetros se sufrirá de sobreajuste. Entonces como estrategia se usa la [\"validación-cruzada\"( cross-validation)](https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada). \n",
    "\n",
    "Una estrategia es subdividir al conjunto de entrenamiento dejando una parte como conjunto de validación. Hay otras estrategias, ya que si son pocos datos puede ser complicado esperar un buen modelo que se entrena en una submuestar pequeña o se puede presentar la situación donde los datos son tomados con ciertos periódos de tiempo, así que ese efecto debe de ser considerado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División entre train y test data.\n",
    "\n",
    "Para el tutorial se hace uso de la función `train_test_split()`. Se hacen dos ejemplos el primero con datos de prueba que contienen scikit-learn y otro con datos del directorio DataSets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de la muestra es\n",
      "(569, 30)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "Cancer=load_breast_cancer()\n",
    "print(\"El tamaño de la muestra es\")\n",
    "print(Cancer.data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan los datos y se dividirán en 80% para entrenamiento (train) y 20% para prueba (test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de la muestra de entrenamiento es:\n",
      "(455, 30)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Cancer.data,Cancer.target,train_size=.8,random_state=123)\n",
    "\n",
    "print(\"El tamaño de la muestra de entrenamiento es:\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que el tamaño de la muestra de entrenamiento es del 80% del total de datos. En el código anterior se agregó la variable de \"salida\" de nombre `Cancer.target`. Se agrega ya que se divide la muestra de datos de las variables predictoras como la variable dependiente.\n",
    "\n",
    "Para completar el ejemplo, estimamos una regresión lineal como modelo para estos datos y medimos el error absoluto medio como una medida de qué tan bueno es el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El error absoluto medio es: 0.177623046678\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "Modelo=LinearRegression()\n",
    "Modelo.fit(X_train,y_train)\n",
    "Pred=Modelo.predict(X_test)\n",
    "\n",
    "print(\"El error absoluto medio es: %s\"%(mean_absolute_error(y_test,Pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código anterior muestra el proceso que se sigue en general:\n",
    "\n",
    "* Se dividen la muestra de datos.\n",
    "* Se estima el modelo sobre los datos de entrenamiento.\n",
    "* Se calcula una predicción del modelo con los datos de prueba.\n",
    "* Se usa algún estadístico  o métrica para ver la calidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segundo ejemplo\n",
    "\n",
    "Se usan datos desde el directorio *DataSets*, se utiliza el archivo `parkinson.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E tamaño de la muestra es:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(195, 24)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No cargamos librerías ya que previamente lo realizamos\n",
    "\n",
    "Datos=pd.read_csv(\"DataSets/parkinsons.csv\")\n",
    "print(\"E tamaño de la muestra es:\")\n",
    "Datos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La diferencia con el ejemplo anterior es que los datos de scikit-learn, están preparados y separados entre los datos y las varible a predecir. \n",
    "\n",
    "Para este caso de hace una breve revisión y preparación de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer    ...     \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374    ...      \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134    ...      \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233    ...      \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492    ...      \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425    ...      \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se visualizan los primeros 5 registros del archivo\n",
    "\n",
    "Datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable a predecir es categorica y tiene por nombre **status**, entonces necesitamos quitar esa variable de los datos y dejara como *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las columnas que se tienen en los datos son:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['name', 'MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
       "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
       "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
       "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'RPDE', 'DFA', 'spread1',\n",
       "       'spread2', 'D2', 'PPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se preparan los datos\n",
    "Status=Datos.status.copy()\n",
    "#Se elimna la variable status\n",
    "del(Datos['status'])\n",
    "#Visualizamos las variables\n",
    "print(\"Las columnas que se tienen en los datos son:\")\n",
    "Datos.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividimos la muestra de datos pero ahora tratamos de mantener el mismo \"balance\" entre las dos muestras. Con esto se trata de decir, que buscamos que la variable **status** sea divida de manera balanceada para los datos de entrenamiento y prueba.\n",
    "\n",
    "Con la palabra **balanceada** se trata de indicar que la se busca que la división entre train/test se realice buscando respetar los porcentajes de cada categoría de la variable **status**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valance de la muestras es:\n",
      "Porcentaje de la variable Estatus para entrenamiento: 0.756410\n",
      "Porcentaje de la variable Estatus para prueba: 0.7435897435897436\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Datos,Status,train_size=.8,random_state=123,stratify=Status)\n",
    "\n",
    "print(\"El valance de la muestras es:\")\n",
    "print(\"Porcentaje de la variable Estatus para entrenamiento: %f\"%(np.sum(y_train)/len(y_train)))\n",
    "print(\"Porcentaje de la variable Estatus para prueba: %s\"%(np.sum(y_test)/len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la muestra de entrenamiento\n",
      "(156, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño de la muestra de entrenamiento\")\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos un modelo de regresión logística para clasificar a los pacientes y ver si están o no con Parkinson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precisión de la clasificacion es: 0.820513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Clasificacion=LogisticRegression()\n",
    "Clasificacion.fit(X_train.iloc[:,1:23],y_train)\n",
    "Pred_Clasificacion=Clasificacion.predict(X_test.iloc[:,1:23])\n",
    "\n",
    "print(\"La precisión de la clasificacion es: %f\"%(accuracy_score(y_test,Pred_Clasificacion)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el código anterios omitimos la variable **name** por eso agregamos la intrucción `X_train.iloc[:,1:23]`, esa variable funciona como la clave o nombre del paciente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "Es importante hacer una buena división de las muestras de datos, hacer una división aleatoria puede no ser la mejor opción ante muchos tipos de datos. No cuidar el balance de alguna variable predictora o no cuidar la distribución, puede ser un tema delicado, ya que se puede elegir el mejor modelo pero no ser bueno para pasarlo a la \"generalización\" ante nuevos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicios\n",
    "\n",
    "En los siguientes ejercicios se hace uso de datos que se tienen por default en *scikit-learn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.- Cargar los datos \"load_diabetes\" y visualiza el tamaño de la muestra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.- Explora el tipo de variable que es el \"target\", si es variable categórica revisa el balance de las \n",
    "#     categorías. En caso de ser continua, revisa la media y mediana usando las funciones de numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.- Divide la muestra en el conjunto de entrenamiento y prueba, con los porcentajes 70/30 y 80/20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.- Elige algún estadístico( la media,la mediana o el porcentaje de las categorías) para revisar cuál es el valor en cada una de las submuestras del ejercicio anterior. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
